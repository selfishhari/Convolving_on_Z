{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_apis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "TEQ-zSOtiVsw",
        "k_RSs04pphob",
        "PLwdpiEH3Nlv",
        "T8awFtP4Q8Gp",
        "FeuHPCA7UJWh"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEQ-zSOtiVsw",
        "colab_type": "text"
      },
      "source": [
        "# Conv(Normal, Dilated, Depthwise separable, Spatially separable) BatchNorm Relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaosJlQ2ocyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvLTUXQ5DFnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchNorm(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, momentum=0.9, epsilon=1e-5):\n",
        "    \n",
        "    super().__init__()\n",
        "    \n",
        "    self.momentum = momentum\n",
        "    \n",
        "    self.epsilon = epsilon\n",
        "    \n",
        "    self.bn = tf.keras.layers.BatchNormalization(momentum=self.momentum, epsilon=self.epsilon)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    \n",
        "    return self.bn(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA9d1lZ5HOxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class spatially_separable_conv(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, filters=32, kernel_size=(3,3), strides=(1,1), padding=\"same\" , dilation_rate=(1,1), kernel_regularizer = None, \n",
        "               kernel_initializer=\"glorot_uniform\"):\n",
        "    \n",
        "    super().__init__()\n",
        "    \n",
        "    k_size1 = (kernel_size[0], 1)\n",
        "    \n",
        "    k_size2 = (1, kernel_size[1])\n",
        "    \n",
        "    self.step1 = tf.keras.layers.Conv2D(filters=filters, kernel_size=k_size1, strides=strides, padding=padding, dilation_rate=dilation_rate,\n",
        "                                       kernel_regularizer=kernel_regularizer, kernel_initializer=kernel_initializer, use_bias=False)\n",
        "    \n",
        "    self.step2 = tf.keras.layers.Conv2D(filters=filters, kernel_size=k_size1, strides=strides, padding=padding, dilation_rate=dilation_rate,\n",
        "                                       kernel_regularizer=kernel_regularizer, kernel_initializer=kernel_initializer, use_bias=False)\n",
        "    \n",
        "  def call(self, inputs):\n",
        "      \n",
        "    return self.step2(self.step1(inputs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmc6IWsNibrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvBnRl(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, filters=32, kernel_size=(3,3), strides=(1,1), padding=\"same\" , dilation_rate=(1,1), kernel_regularizer = None, \n",
        "               kernel_initializer=\"glorot_uniform\", conv_flag=True, bnflag=True,  relu=True, depthwise_separable=False, spatial_separable=False):\n",
        "    \n",
        "    super().__init__()\n",
        "    \n",
        "    self.relu = relu\n",
        "    \n",
        "    self.bn_flag = bnflag\n",
        "    \n",
        "    self.conv_flag = conv_flag\n",
        "    \n",
        "    if depthwise_separable:\n",
        "      \n",
        "      self.conv = tf.keras.layers.SeparableConv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, dilation_rate=dilation_rate,\n",
        "                                       kernel_regularizer=kernel_regularizer, kernel_initializer=kernel_initializer, use_bias=False)\n",
        "    elif spatial_separable:\n",
        "      \n",
        "      self.conv = spatially_separable_conv(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, dilation_rate=dilation_rate, \n",
        "                                           kernel_regularizer = kernel_regularizer, kernel_initializer=kernel_initializer)\n",
        "      \n",
        "    else:\n",
        "      \n",
        "      self.conv = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, dilation_rate=dilation_rate,\n",
        "                                       kernel_regularizer=kernel_regularizer, kernel_initializer=kernel_initializer, use_bias=False)\n",
        "    \n",
        "    \n",
        "    \n",
        "    self.bn = BatchNorm(momentum=0.9, epsilon=1e-5)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    \n",
        "    if self.conv_flag:\n",
        "\n",
        "      if self.relu:\n",
        "\n",
        "        if self.bn_flag:\n",
        "          return tf.nn.relu(self.bn(self.conv(inputs)))\n",
        "\n",
        "        else:\n",
        "          return tf.nn.relu(self.conv(inputs))\n",
        "      else:\n",
        "\n",
        "        if self.bn_flag:\n",
        "          return self.bn(self.conv(inputs))\n",
        "\n",
        "        else:\n",
        "          return self.conv(inputs)\n",
        "        \n",
        "    else:\n",
        "      \n",
        "      if self.relu:\n",
        "\n",
        "        if self.bn_flag:\n",
        "          \n",
        "          return tf.nn.relu(self.bn(inputs))\n",
        "\n",
        "        else:\n",
        "          \n",
        "          return tf.nn.relu(inputs)\n",
        "      else:\n",
        "\n",
        "        if self.bn_flag:\n",
        "          \n",
        "          return self.bn(inputs)\n",
        "\n",
        "        else:\n",
        "          \n",
        "          \"\"\"if conv, bn, rl flags are False, then just return conv\"\"\"\n",
        "          \n",
        "          return self.conv(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1NI_i8_uKcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiSvyJw1pVhO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "eddffe41-ef9b-4401-dd88-3fe49eb9064b"
      },
      "source": [
        "x = ConvBnRl(filters=32, kernel_size=(1,1), strides=(1,1), padding=\"valid\" , dilation_rate=(1,1), kernel_regularizer = None, \n",
        "               kernel_initializer=\"glorot_uniform\", conv_flag=True, bnflag=True,  relu=True, depthwise_separable=True)\n",
        "\n",
        "x(np.random.normal(size=(32,32,3)).reshape(1,32,32,3).astype(np.float16))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0830 15:53:35.675567 140616057554816 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'conv_bn_rl/Relu:0' shape=(1, 32, 32, 32) dtype=float16>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_RSs04pphob",
        "colab_type": "text"
      },
      "source": [
        "# ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMlCtg0Dp3hX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlk(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, \n",
        "               \n",
        "               cbr = ConvBnRl(filters=32, kernel_size=(3,3), strides=(1,1), padding=\"same\" , conv_flag=True, bnflag=True, relu=True),\n",
        "               \n",
        "               cbr_res1 = ConvBnRl(filters=32, kernel_size=(3,3), strides=(1,1), padding=\"same\" , conv_flag=True, bnflag=True, relu=True),\n",
        "               \n",
        "               cbr_res2 = ConvBnRl(filters=32, kernel_size=(3,3), strides=(1,1), padding=\"same\" , conv_flag=True, bnflag=True, relu=True),\n",
        "               \n",
        "               pool=tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2,2), padding='same'), \n",
        "               \n",
        "               res=True ):\n",
        "    \n",
        "    super().__init__()\n",
        "    \n",
        "    self.conv_bn = cbr\n",
        "    \n",
        "    self.pool = pool\n",
        "    \n",
        "    self.res = res\n",
        "    \n",
        "    if self.res:\n",
        "      \n",
        "      self.res1 = cbr_res1\n",
        "      \n",
        "      self.res2 = cbr_res2\n",
        "\n",
        "  def call(self, inputs):\n",
        "    \n",
        "    h = self.pool(self.conv_bn(inputs))\n",
        "    \n",
        "    if self.res:\n",
        "      \n",
        "      h = h + self.res2(self.res1(h))\n",
        "      \n",
        "    return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmB5q_Cbv7bl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "202d4766-c9eb-46de-d7bf-cc7d69ee4898"
      },
      "source": [
        "a = ResBlk()\n",
        "\n",
        "a(x(np.random.normal(size=(32,32,3)).reshape(1,32,32,3).astype(np.float16)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'res_blk/add:0' shape=(1, 16, 16, 32) dtype=float16>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sub9VoYQ2Mg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLwdpiEH3Nlv",
        "colab_type": "text"
      },
      "source": [
        "# ResNext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjZcjt6D3PiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNeXtBlk(tf.keras.Model):\n",
        "  \n",
        "    def __init__(self, \n",
        "                 \n",
        "                 layer_num, \n",
        "                 \n",
        "                 filters=32, \n",
        "                 \n",
        "                 pool=tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='same'), \n",
        "                 \n",
        "                 kernel_regularizer=None,\n",
        "                 \n",
        "                 kernel_initializer=\"glorot_uniform\",\n",
        "                 \n",
        "                 res_block=1, cardinality=8):\n",
        "      \n",
        "      super().__init__()\n",
        "      \n",
        "      self.filters = filters\n",
        "      \n",
        "      self.layer_num = layer_num\n",
        "      \n",
        "      self.res_block=res_block\n",
        "      \n",
        "      self.kernel_regularizer = kernel_regularizer\n",
        "      \n",
        "      self.kernel_initializer = kernel_initializer\n",
        "      \n",
        "      self.conv_bn_1x1 = ConvBnRl(filters=self.filters, kernel_size=(1,1), strides=(1,1), padding=\"same\" , dilation_rate=(1,1), \n",
        "                                  kernel_regularizer = self.kernel_regularizer, kernel_initializer=self.kernel_initializer, conv_flag=True, bnflag=True,  relu=True)\n",
        "      \n",
        "      self.conv_bn_3x3 = ConvBnRl(filters=self.filters, kernel_size=(3,3), strides=(1,1), padding=\"same\" , dilation_rate=(1,1), \n",
        "                                  kernel_regularizer = self.kernel_regularizer, kernel_initializer=self.kernel_initializer, conv_flag=True, bnflag=True,  relu=True)\n",
        "      \n",
        "      \n",
        "      self.cardinality = cardinality\n",
        "      \n",
        "      self.pool = pool\n",
        "      \n",
        "    def concatenation(self, layers) :\n",
        "      \n",
        "            return tf.keras.layers.concatenate(layers, axis=3)       \n",
        "\n",
        "    def first_layer(self, x, scope):\n",
        "        with tf.name_scope(scope) :\n",
        "            \n",
        "            x = self.conv_bn_3x3(x)\n",
        "\n",
        "            return x\n",
        "\n",
        "    def transform_layer(self, x, depth, pool_flag, scope):\n",
        "        with tf.name_scope(scope) :\n",
        "          \n",
        "            if pool_flag:\n",
        "              \n",
        "              x = self.pool(x)\n",
        "          \n",
        "            cbr_1x1 = ConvBnRl(filters=depth, kernel_size=(1,1), strides=(1,1), padding=\"same\" , dilation_rate=(1,1), \n",
        "                                  kernel_regularizer = self.kernel_regularizer, kernel_initializer=self.kernel_initializer, conv_flag=True, bnflag=True,  relu=True)\n",
        "            \n",
        "            x = cbr_1x1(x)\n",
        "            \n",
        "            cbr_3x3 = ConvBnRl(filters=depth, kernel_size=(3,3), strides=(1,1), padding=\"same\" , dilation_rate=(1,1), \n",
        "                                  kernel_regularizer = self.kernel_regularizer, kernel_initializer=self.kernel_initializer, conv_flag=True, bnflag=True,  relu=True)\n",
        "            \n",
        "            x = cbr_3x3(x)\n",
        "\n",
        "            return x\n",
        "\n",
        "    def transition_layer(self, x, filters, scope):\n",
        "        with tf.name_scope(scope):\n",
        "          \n",
        "            cb_1x1 = ConvBnRl(filters=filters, kernel_size=(1,1), strides=(1,1), padding=\"same\" , dilation_rate=(1,1), \n",
        "                                  kernel_regularizer = self.kernel_regularizer, kernel_initializer=self.kernel_initializer, conv_flag=True, bnflag=True,  relu=True)\n",
        "            \n",
        "            x = cb_1x1(x)\n",
        "\n",
        "            return x\n",
        "\n",
        "    def split_layer(self, input_x, filters, pool_flag, layer_name):\n",
        "      \n",
        "        with tf.name_scope(layer_name) :\n",
        "          \n",
        "            layers_split = list()\n",
        "            \n",
        "            depth = filters//self.cardinality\n",
        "            \n",
        "            for i in range(self.cardinality) :\n",
        "              \n",
        "                splits = self.transform_layer(input_x, depth, pool_flag=pool_flag, scope=layer_name + '_splitN_' + str(i))\n",
        "                \n",
        "                layers_split.append(splits)\n",
        "\n",
        "            return self.concatenation(layers_split)\n",
        "\n",
        "    def residual_layer(self, input_x):\n",
        "        # split + transform(bottleneck) + transition + merge\n",
        "\n",
        "        for i in range(self.res_block):\n",
        "            # input_dim = input_x.get_shape().as_list()[-1]\n",
        "            input_dim = int(np.shape(input_x)[-1])\n",
        "\n",
        "            if input_dim * 2 == self.filters:\n",
        "              \n",
        "                flag = True\n",
        "                \n",
        "                stride = 2\n",
        "                \n",
        "                channel = input_dim // 2\n",
        "                \n",
        "            else:\n",
        "              \n",
        "                flag = False\n",
        "                \n",
        "                stride = 1\n",
        "                \n",
        "            x = self.split_layer(input_x, filters=self.filters, pool_flag=flag, layer_name='split_layer_'+self.layer_num+'_'+str(i))\n",
        "            \n",
        "            x = self.transition_layer(x, filters=self.filters, scope='trans_layer_'+self.layer_num+'_'+str(i))\n",
        "\n",
        "            if flag is True :\n",
        "                \n",
        "                pad_input_x = self.pool(input_x)\n",
        "                \n",
        "                pad_input_x = tf.pad(pad_input_x, [[0, 0], [0, 0], [0, 0], [channel, channel]]) # [?, height, width, channel]\n",
        "                \n",
        "                \n",
        "                \n",
        "            else :\n",
        "                pad_input_x = input_x\n",
        "                \n",
        "            input_x = tf.nn.relu(x + pad_input_x)\n",
        "        \n",
        "        return input_x\n",
        "      \n",
        "    def call(self, inputs_x):\n",
        "        \n",
        "        return self.residual_layer(inputs_x)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54BUAHsbPa3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6176bdfe-cb87-4e02-fbba-2568a775c41e"
      },
      "source": [
        "b = ResNeXtBlk(layer_num=\"1\")\n",
        "\n",
        "b(a(x(np.random.normal(size=(32,32,3)).reshape(1,32,32,3).astype(np.float16))))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'res_ne_xt_blk_1/Relu:0' shape=(1, 16, 16, 32) dtype=float16>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga_w3xzzPcSs",
        "colab_type": "text"
      },
      "source": [
        "# Inception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhirZ0vCBnyu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b74730a5-cbd3-480a-d2fe-4bbaa82094a1"
      },
      "source": [
        "\"\"\"class InceptionBlk(tf.keras.Model):\n",
        "  \"\"\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'res_ne_xt_blk/Relu:0' shape=(1, 16, 16, 32) dtype=float16>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8awFtP4Q8Gp",
        "colab_type": "text"
      },
      "source": [
        "# ResNext_50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmGxmuZeQ6lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNext_50(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, num_classes= 10, f_filter=32):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    \n",
        "    self.first_layer = ConvBnRl(filters=f_filter, kernel_size=(1,1), strides=(1,1), padding=\"same\" , dilation_rate=(1,1), \n",
        "                                  kernel_regularizer = None, kernel_initializer='glorot_uniform', conv_flag=True, bnflag=True,  relu=True)\n",
        "\n",
        "    self.blk1 = ResNeXtBlk(filters=f_filter, layer_num='1')\n",
        "\n",
        "    self.blk2 = ResNeXtBlk(filters=f_filter*2, layer_num='2')\n",
        "\n",
        "    self.blk3 = ResNeXtBlk(filters=f_filter*4, layer_num='3')\n",
        "\n",
        "    self.pool = tf.keras.layers.GlobalMaxPool2D()\n",
        "\n",
        "    self.linear = tf.keras.layers.Dense(num_classes, kernel_initializer='glorot_uniform', use_bias=False)\n",
        "  \n",
        "  def call(self, x, y):\n",
        "        \n",
        "        x = self.first_layer(x)\n",
        "\n",
        "        x = self.blk1(x)\n",
        "        \n",
        "        x = self.blk2(x)\n",
        "        \n",
        "        x = self.blk3(x)\n",
        "\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = self.linear(x)\n",
        "        \n",
        "        ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=x, labels=y)\n",
        "    \n",
        "        loss = tf.reduce_sum(ce)\n",
        "    \n",
        "        correct = tf.reduce_sum(tf.cast(tf.math.equal(tf.argmax(x, axis = 1), y), tf.float32))\n",
        "      \n",
        "        return loss, correct\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzwi5w2DSQB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "522f5479-f54b-43a1-cdda-c24ce9c77762"
      },
      "source": [
        "resnext_model = ResNext_50(num_classes=10)\n",
        "\n",
        "resnext_model(np.random.normal(size=(32,32,3)).reshape(1,32,32,3).astype(np.float16), \n",
        "              np.array([1]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor 'res_next_50_6/Sum:0' shape=() dtype=float16>,\n",
              " <tf.Tensor 'res_next_50_6/Sum_1:0' shape=() dtype=float32>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeuHPCA7UJWh",
        "colab_type": "text"
      },
      "source": [
        "# DavidNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z75GhTB7S39l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DavidNet(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, num_classes= 10, f_filter=32, weight=0.125):\n",
        "    \n",
        "    super().__init__()\n",
        "    \n",
        "    self.init_conv_bn = ConvBnRl(filters=f_filter, kernel_size=(1,1), strides=(1,1), padding=\"same\" , dilation_rate=(1,1), \n",
        "                                  kernel_regularizer = None, kernel_initializer='glorot_uniform', conv_flag=True, bnflag=True,  relu=True)\n",
        "    \n",
        "    self.blk1 = ResBlk(cbr = ConvBnRl(filters=f_filter, kernel_size=(3,3), strides=(1,1), padding=\"same\" , conv_flag=True, bnflag=True, relu=True),\n",
        "               \n",
        "               cbr_res1 = ConvBnRl(filters=f_filter, kernel_size=(3,3), strides=(1,1), padding=\"same\" , conv_flag=True, bnflag=True, relu=True),\n",
        "               \n",
        "               cbr_res2 = ConvBnRl(filters=f_filter, kernel_size=(3,3), strides=(1,1), padding=\"same\" , conv_flag=True, bnflag=True, relu=True),\n",
        "               \n",
        "               pool=tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='same'), \n",
        "               \n",
        "               res=True )\n",
        "    \n",
        "    self.blk2 = ResBlk(cbr = ConvBnRl(filters=f_filter*2, kernel_size=(3,3), strides=(1,1), padding=\"same\" , conv_flag=True, bnflag=True, relu=True),\n",
        "               \n",
        "               cbr_res1 = ConvBnRl(filters=f_filter*2, kernel_size=(3,3), strides=(1,1), padding=\"same\" , conv_flag=True, bnflag=True, relu=True),\n",
        "               \n",
        "               cbr_res2 = ConvBnRl(filters=f_filter*2, kernel_size=(3,3), strides=(1,1), padding=\"same\" , conv_flag=True, bnflag=True, relu=True),\n",
        "               \n",
        "               pool=tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='same'), \n",
        "               \n",
        "               res=True )\n",
        "    \n",
        "    self.blk3 = ResBlk(cbr = ConvBnRl(filters=f_filter*3, kernel_size=(3,3), strides=(1,1), padding=\"same\" , conv_flag=True, bnflag=True, relu=True),\n",
        "               \n",
        "               cbr_res1 = ConvBnRl(filters=f_filter*3, kernel_size=(3,3), strides=(1,1), padding=\"same\" , conv_flag=True, bnflag=True, relu=True),\n",
        "               \n",
        "               cbr_res2 = ConvBnRl(filters=f_filter*3, kernel_size=(3,3), strides=(1,1), padding=\"same\" , conv_flag=True, bnflag=True, relu=True),\n",
        "               \n",
        "               pool=tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='same'), \n",
        "               \n",
        "               res=True )\n",
        "    \n",
        "    self.pool = tf.keras.layers.GlobalMaxPool2D()\n",
        "    \n",
        "    self.linear = tf.keras.layers.Dense(num_classes, kernel_initializer='glorot_uniform', use_bias=False)\n",
        "    \n",
        "    self.weight = weight\n",
        "\n",
        "  def call(self, x, y):\n",
        "    \n",
        "    h = self.pool(self.blk3(self.blk2(self.blk1(self.init_conv_bn(x)))))\n",
        "    \n",
        "    h = self.linear(h) * self.weight\n",
        "    \n",
        "    ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=h, labels=y)\n",
        "    \n",
        "    loss = tf.reduce_sum(ce)\n",
        "    \n",
        "    correct = tf.reduce_sum(tf.cast(tf.math.equal(tf.argmax(h, axis = 1), y), tf.float16))\n",
        "    \n",
        "    return loss, correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQes5p0hVlwy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9b1636b4-096d-4594-a6a3-f597cfd2eb6d"
      },
      "source": [
        "davidnet_model = DavidNet(num_classes=10)\n",
        "\n",
        "davidnet_model(np.random.normal(size=(32,32,3)).reshape(1,32,32,3).astype(np.float16), \n",
        "              np.array([1]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor 'david_net/Sum:0' shape=() dtype=float16>,\n",
              " <tf.Tensor 'david_net/Sum_1:0' shape=() dtype=float16>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zY0cElSVs7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}